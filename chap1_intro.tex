%%% -*-LaTeX-*-

\chapter{Introduction}

\section{Concurrent Software Correctness}

In the life-cycle of computer programs, software testing and debugging play essential roles.
%
Many approaches have been developed to test and debug software at different layers and from different aspects.
%
Traditional and basic debugging techniques such as ``printf'' debugging, interactive debugging, memory dumps, and profiling have been used widely in software development.
%
%
However, with the high growth in computation power and modern languages, programs are getting more sophisticated, complex, large, and heterogeneous to efficiently exploit the processing power (e.g., Cloud computing, High Performance Computing - HPC).
%
Locating bugs in concurrent software is notoriously challenging because: 1) the interleaving space grows exponentially with the number of processing units (\eg, CPU cores), 2) the non-deterministic nature of concurrent software makes concurrent bugs difficult to reproduce, and 3) root-causing misbehaved executions of a concurrent program is non-trivial due to the complex interactions between concurrent components of the program.
%

\subsection{Concurrent Bugs}
\subsubsection{Deadlocks}
\subsubsection{Misuse of Serialization/Synchronization}
\paragraph{Race}
\paragraph{Atomicity Violations}

\subsection{Concurrent Debuggers}
\subsubsection{Race Checkers}
\subsubsection{Static Analyzers}
\paragraph{Assertion-based Debugging}
\paragraph{Model Checking}
\paragraph{Theorem Proving}
\subsubsection{Dynamic Analyzers}
\paragraph{Tracing}
\paragraph{Visualization}
\subsubsection{Hybrid Analyzers}
\paragraph{Record and Replay}
\paragraph{Testing}


\section{Dissertation Statement}
Today's programs are designed to exploit the power of modern processing units. Efficiently collecting data and systematically analyze them is an effective way to gain insight into the behavior of complex programs and help developers fix the flaws of the program.

\section{Background}
\par{ \textbf{Goal one: Heterogeneity} ---
Many computation-based scientific problems like gene sequence alignment in biology, climate simulations and stencil codes are implemented to execute on supercomputers.
%
Depending on the problem domain, HPC applications apply a wide range of programming languages, compilers, and optimizations to solve problems.
%
Besides, HPC applications are often implemented for a particular architecture to maximize performance.
%
Moreover, different types of faults might occur at different levels.
%
There exist debugging tools that target a specific domain, architecture, programming language, or particular classes of bugs.
%
However, the applied techniques in such tools might not prove effective for other domains or bug types.
%
In this work, we propose a general-purpose infrastructure to collect comprehensive data from an application regardless of its domain, compiler, and programming language by tracing at the binary level.
%
}
\par{ \textbf{Goal two: Scalability} ---
Powerful supercomputers are deployed to execute the HPC application on a massive scale to achieve high throughput.
%
The high throughput implies that many processing units are busy with executing instructions or communicating with each other in parallel.
%
Enough evidence needs to get gathered during the execution from each processing unit (process, thread, task) to understand the computation and communication behavior of the program.
%
Also, some abnormal behaviors may only get triggered and manifest when executed on larger scales.
%
Thus it is essential to have a mechanism to collect sufficient data during the execution of HPC applications on a massive scale.
%
However, capturing the per-processing-unit events requires \textit{control events} to attach to each original event (e.g., function calls).
%
Placing and executing these other control events adds overhead to the application execution and might hurt the performance.
%
In addition, the collected data from each processing unit have to transfer through system and network bandwidth for the analysis phase.
%
Special care for instrumenting and gathering data is essential to preserve the performance of the native application.
%
On the other hand, during the execution of HPC applications, each processing unit or node contains a large number of \textit{events} to capture.
%
Thus long-running large scale applications often leave an overwhelming amount of data to analyze.
%
The search space rapidly grows as the scale of application execution increases.
%
Having an efficient \textit{data collection} mechanism to overcome the trade-off between \textit{comprehensive information} and \textit{low overhead}, is another motivation of this dissertation.
%
}
\par{ \textbf{Goal Three: Intuitition} ---
The effort towards saving significant energy causes the non-intuitive behavior of HPC applications.
%
Floating-point reduction, low-buffering message passing, non-determinism of application, and collective operations are just some examples of uncertain behavior of HPC applications.
%
Root causing the unsuccessful execution of these kinds of applications is not achievable by ad hoc debuggers.
%
The efficient data collection during program execution enables developers to post-mortem analyze the collected data from different aspects.
%
Given the one-time gathered data, the behavior of the program execution can be studied iteratively, from various angles on each iteration.
%
In this dissertation, different data abstraction and visualization techniques are applied to bring intuition and reveal interesting facts about the program behavior from a purposeful point of view.

\section{Contributions of the Dissertation}
\begin{itemize}
  \item We introduce \parlot, a whole-program call tracing framework for HPC applications (MPI+X) that highly compresses the traces (up to more than 21000 times) while adding minimal overhead with average required bandwidth of just 56 kB/s per core.
  \item We present DiffTrace, a series of automated data abstraction, representation and visualization techniques that differntiates the collected ParLOT traces and narrows the search down to just a few candidates of buggy traces.
  \item We illustrate \goat, an end-to-end framework for automated tracing, analysis and testing of concurrent Go applications.
  \item We propose a set of coverage metrics to measure the quality of testing in CSP-like concurrent languages.
\end{itemize}

\section{Organization of the Dissertation}
\begin{itemize}
  \item Efficient Whole-Program Tracing (\parlot)
  \item Whole-Program Trace Analysis for Debugging (DiffTrace)
  \item End-to-end Analysis Framework for Concurrent Go (Goat)
\end{itemize}
