\subsection{Nested Loop Recognition (NLR)}
\label{subsec:algo-nlr}

We build NLRs based on the work by Ketterlin and Clauss~\cite{Ketterlin-nlr},
who use this algorithm for trace compression,
and the work by Kobayashi and MacDougall~\cite{kobayashi-84}, who propose
a similar bottom-up strategy to build loop nests from traces,
replacing each recognized loop with a new symbol.
%(sequence of string instructions) where each
%is originally designed for prediction and compression of data access traces (memory addresses) through detecting the ``linear progression function'' in the sequence of addresses.
%
%Two main operations of NLR algorithm are 1) recognizing the start of a loop and forming its initial syntactic structure and 2) recognizing if what follows a loop is just another iteration and extend the upper bound.
%
%These operations are performed incrementally and recursively to recognize loops at different depths (i.e., a linear function of the loop index and depth) until the input sequence is completely consumed and no more loop is detected.
%
%
%we have re-implemented the NLR algorithm (DiffTrace-NLR) for detecting repetitive patterns
We adapt these algorithms
to function-call traces
wherein we record
identical loops at different locations by introducing
a single new (made-up) function ID that represents the entire loop.
%
This process is restarted once the whole trace has been analyzed for depth-2 loops and so on until a function-ID replacement is performed.
%
DiffTrace-NLR works by incrementally pushing trace entries (function IDs)
onto a stack of \textit{elements} (i.e., function IDs
representing detected loop structures).
%
Whenever an element is pushed onto the stack $S$,
the upper elements of the stack are recursively
examined for potential loop detection or loop extensions (Procedure \ref{proc:NLR}).


\begin{small}
\begin{algorithm}[]
 \DontPrintSemicolon
 \SetKwFunction{KwReduce}{Reduce}
% \SetKwInOut{Input}{Input} \SetKwInOut{Output}{Output}\SetKwInOut{Local}{Local}
  %\SetKw{KwEach}{each}
 %\Input{Stack of elements $S$, $S[1]$ is top}
 %\Output{$NLR(T)$}
 \KwReduce{$S$}:{\\
 \Indp
     \For{$ i:1$ ... $3K$}{
         $b$ = $i/3$\;
         \If{Top 3 $b$-long elements of $S$ are \textit{isomorphic}}{
             pop $i$ elements from $S$\;
             $LB=S[b:1]$,
             $LC=3$\;
             $LS=(LB,LC)$\;
             push $LS$ to $S$\;
             add $LB$ to the Loop Table\;
             \KwReduce{$S$}\;
         }
         \If{ $S[i]$ is a loop ($LS$) and $S[i-1:1]$ isomorphic to its loop body$LB$}{
             $LC=LC+1$\;
             pop $i-1$ elements from $S$\;
             \KwReduce{$S$}\;
         }
     }
 }

 \caption{\texttt{Reduce} procedure adapted from the NLR algorithm }
 \label{proc:NLR}
\end{algorithm}
\end{small}

% Each loop structure \textbf{LS} is a tuple of (loop body \textbf{LB}, loop count \textbf{LC}) where LB is a sequence of elements, and LC is an integer showing the frequency of consecutive occurrence of LB.
% %
% To avoid coincidental regularity, the algorithm needs at least \textit{three} consecutive terms to form an LS.
% %
% The \texttt{Reduce} procedure checks to see if any three consecutive subsequences on top of the stack are \textit{isomorphic}.
% %
% In our context, two sequences are isomorphic if both have equal lengths and identical corresponding elements.
% %
% If the check passes, then the top three consecutive subsequences (LB) are popped from the stack, and the LS=(LB,3) is pushed onto the stack. Otherwise, top elements of the stack are compared against the potential LS behind them to increment the LC in case of isomorphism.
% If either of the above examinations succeeds, the procedure restarts on the recently modified stack for detecting or extending potential nested loops.
%

We store all distinct loop bodies (LBs)
in a hash-table, assigning each a unique ID, which can be applied as
a heuristic to detect loops not only in the current trace but also in other
traces of the same execution.
%
The maximum length of the subsequences to examine is decided by a fixed $K$.
%
The complexity of the NLR algorithm is $\Theta(K^2N)$ where $N$ is the size of the input.
%
While loop detection has been researched in other contexts,
its use to support debugging is believed to be novel.

\subsection{Concept Lattice Construction}
\label{subsec:algo-cl}

%There exist algorithms that extract concepts and their partial order from a formal context; each has its pros and cons.
%
The efficiency of algorithms for concept lattice construction
depends on the sparseness of the formal context~\cite{clgenperform}.
%
%Based on the sparseness of the formal context,
%the
%
Ganter's \textit{Next Closure} algorithm \cite{clbook}
constructs the lattice from a
\textit{batch} of contexts and requires the whole context to be present in main memory and is, therefore, inefficient for long HPC traces.
%
%For large scale HPC traces, such an approach is inefficient.
%
\input{diffTrace/tabs/attributes.tex}
%
We have implemented Godin's \textit{incremental} algorithm \cite{clconst}
to extract attributes (Table \ref{tab:atr})
from each trace (object) and inject them into an initially empty lattice.
%
Notice that our representation already includes compression of the attributes as (1) either the
observed frequency is recorded, (2) the log10 of the frequency is recorded, or (3) ``no frequency''
(presence/absence) of a function call is recorded.
%
{\em These are versatile knobs to adjust for bug-location and similarity calculation}.


Every time a new object with its set of attributes is added to the lattice,
an \textit{update} procedure minimally modifies/adds/deletes edges and nodes of the lattice.
%
%This procedure is guaranteed to preserve the validity of the concept lattice properties.
%
The extracted attributes are in the form \textit{\{attr:freq\}}.
%
\textit{attr} is either a single entry of the trace NLR or a consecutive pair of entries.
\textit{freq} is a parameter to adjust the impact of the frequency of each \textit{attr}
in the concept lattice.
%
The complexity of Godin's algorithm is $O(2^{2K}|G|)$, where $K$ is an upper bound for the number of attributes (e.g., distinct function calls in the whole execution) and $|G|$ is the number of objects (e.g., the number of traces).

%In DiffTrace, the upper bound for the number of attributes is usually small since traces are pre-processed and summarized in the form of NLRs. Thus Godin's algorithm would perform near



\subsection{Hierarchical Clustering, Construction, and Comparison}
\label{subsec:algo-bscore}

 DiffJSMs provide pair-wise dissimilarity
 measurements that can be used to combine traces (forming initial clusters).
%
% However, to derive a flat clustering of traces to detect the outlier(s)
To obtain outliers (suspicious traces),
we form dendrograms for which
a \textit{linkage} function is required to measure the distance between sets of traces.
%
 We currently employ SciPy (version 1.3.0. \cite{scipy}) for these tasks.
% for clustering and obtaining
% the table of suspicious traces.
%derived from the DiffJSM by hierarchical clustering algorithms in
%
%
 SciPy provides a wide range of linkage functions
 such as single, complete, average, weighted, centroid, median, and ward.

\subsubsection{Ranking Table}
As shown in Figure \ref{fig.diffTraceOverview},
each component of DiffTrace has some tunable parameters and constants,
and the suggested suspicious traces are a function of them.
%
Thus, a metric is needed to serve as the sorting key of the suspicious traces.
%
Each parameter combination, in essence, creates a different DiffJSM,
giving us ``the distance between two hierarchical clusterings''.
%
Fowlkes et al.~\cite{fowlkes83} proposed a method for comparing two
hierarchical clusterings by computing their \textit{B-score}.
%
%The B-score of two clusterings is computed by counting the number of objects that fall into different clusters.
%%
While we have not evaluated the full relevance of this idea,
our initial experiments show that sorting suspicious traces based on the B-score of DiffJSMs is
effective and brings interesting outliers to attention.
%--end
