%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tracing Overhead
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Tracing Overhead}
\label{subsec:lowtoh}
\input{parlot/tabs.comet.newMed/comet_bw_pMpAcg_BC_itn_p3.5.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FROM RESULTS - average bandwidth
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[b]
\centering
\includegraphics[width=.75\textwidth]{parlot/figs.comet.newMed/comet_chartAvg_bw_B_p3_5.png}
\caption{  Average required bandwidth per core (kB/s) on the NPB applications - Input B}
\label{comet_chartAvg_bw_B_p3_5}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=.75\textwidth]{parlot/figs.comet.newMed/comet_chartAvg_bw_C_p3_5.png}
\caption{ Average required bandwidth per core (kB/s) on the NPB applications - Input C}
\label{comet_chartAvg_bw_C_p3_5}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ENDDDD
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Table \ref{comet_sd_pMpAcg_BC_itn_p3.5} shows the tracing overhead of \parlotm, \parlota, and \callgrind on each application of the NPB benchmark suite for different node counts. The last column of the table lists the geometric mean over all eight programs. The AVG rows show the average over the four node counts.


On average, both \parlotm and \parlota outperform \callgrind. The bolded numbers in Table \ref{comet_sd_pMpAcg_BC_itn_p3.5} for input C show that the average overhead is 1.94 for \parlotm, 2.73 for \parlota, and 4.63 for \callgrind. Figures \ref{comet_chartAvg_sd_B_p3_5} and \ref{comet_chartAvg_sd_C_p3_5} show these results in visual form.


The key takeaway point is that the overhead of \parlot is roughly a factor of two to three, which we believe users may be willing to accept, for example, if it helps them debug their applications. This is promising especially when considering how detailed the collected trace information is and that most of the overhead is due to \pin (see \S\ref{subsec:pinit}). Note that \parlot 's overhead is typically lower than that of \callgrind, which collects less information.

The overhead of \parlot increases as we scale the applications to more compute nodes. However, the increase is quite small. Going from 16 to 1024 cores, a 64-fold increase in parallelism, only increases the average overhead by between 1.3- and 2.1-fold. In contrast, \callgrind's overhead decreases with increasing node count, making it more scalable. Having said that, \callgrind's overhead is larger for the C inputs whereas \parlot 's overhead is larger for the smaller B inputs. In other words, \parlot scales better to larger inputs than \callgrind.

\parlot's scaling behavior can be explained by correlating it with the expected function-call frequency. When distributing a fixed problem size over more cores, each core receives less work. As a consequence, less time is spent in the functions that process the work, resulting in more function calls per time unit, which causes more work for \parlot. In contrast, when distributing a larger problem size over the same number of cores, each core receives more work. Hence, more time is spent in the functions that process the work, resulting in fewer function calls per time unit, which causes less work for \parlot and therefore less tracing overhead. Hence, we believe \parlot 's overhead to be even lower on long-running inputs, which is where our tracing technique is needed the most.


In summary, \parlot 's overhead is in the single digits for all evaluated applications and configurations, including for 1024-core runs. It appears to scale reasonably to larger node counts and well to larger problem sizes.

\subsection{Required Bandwidth}
\label{subsec:lowbw}

Table \ref{comet_bw_pMpAcg_BC_itn_p3.5}, Fig.  \ref{comet_chartAvg_bw_B_p3_5} and Fig. \ref{comet_chartAvg_bw_C_p3_5} show how much trace bandwidth each tool
requires
during the application execution.
%
On average, \parlotm requires less bandwidth than
\callgrind, especially for smaller inputs.
%
\parlota's bandwidth is much higher as it collects call information from all
images and not just the main image like \parlotm does.

We see that the required bandwidth for different input sizes of the NPB applications are almost equal in \parlot. According to the NPB documentation, the number of iterations for inputs B and C are the same for all applications. They only differ in the number of elements or the grid size. It is clear that the required bandwidth of \parlot is independent of the problem size, unlike \callgrind, where the input size has a linear impact on the results.

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FROM RESULTS - average compression ratio
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[b]
\centering
\includegraphics[width=.75\textwidth]{parlot/figs.comet.newMed/comet_chartAvg_cr_B_p3_5.png}
\caption{ Average compression ratio of \parlot on the NPB applications - Input B}
\label{comet_chartAvg_cr_B_p3_5}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=.75\textwidth]{parlot/figs.comet.newMed/comet_chartAvg_cr_C_p3_5.png}
\caption{ Average compression ratio of \parlot on the NPB applications - Input C}
\label{comet_chartAvg_cr_C_p3_5}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ENDDDD
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\input{parlot/tabs.comet.newMed/comet_cr_pMpA_BC_itn_p3.5.tex}



\begin{figure}[b]
\centering
\includegraphics[width=.75\textwidth]{parlot/figs.comet.newMed/comet_chartDet_B_wc_byTool_p3_5.png}
\caption{ Tracing overhead breakdown - Input B}
\label{comet_chartDet_B_wc_byTool_p3_5}
\end{figure}


\begin{figure}[t]
\centering
\includegraphics[width=.75\textwidth]{parlot/figs.comet.newMed/comet_chartDet_C_wc_byTool_p3_5.png}
\caption{ Tracing overhead breakdown - Input C}
\label{comet_chartDet_C_wc_byTool_p3_5}
\end{figure}



\begin{figure}[t]
\centering
\includegraphics[width=.75\textwidth]{parlot/figs.comet.newMed/comet_BX2_Main_16_B_p3_5.png}
\caption{ Variability of \parlotm overhead on 16 nodes - Input B}
\label{comet_BX2_Main_16_B_p3_5}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Compression Ratio}
\label{subsec:cr}
Table \ref{comet_cr_pMpA_BC_itn_p3.5} shows the compression ratios for all configurations and inputs.
%
On average, \parlot stores between half a kilobyte and a kilobyte of trace information in a single byte.
%
We observe that the
average compression ratio for \parlota on input C is 644.3, and its
corresponding required bandwidth from Table
\ref{comet_bw_pMpAcg_BC_itn_p3.5} is 56.4 kB/s.
%
This means \parlot can
collect \textbf{more than 36 MB} worth of data per core per second
while only needing 56 kB/s of the system bandwidth, {\em leaving the rest of the available bandwidth to the application.}
%
In comparison, \callgrind
collects \textbf{less than 100 kB} of data but still adds more
overhead compared to either \parlota or \parlotm .
%
The average amount of trace data that can be collected by \parlota is
\textbf{360x} (85x for \parlotm) larger than that for \callgrind.
%
In the best observed case, the compression ratio of
\parlot exceeds 21000.
%
This is particularly impressive because it was achieved with relatively low overhead and incremental
on-the-fly compression.
%
Generally, the compression ratios of \parlotm are higher than those of \parlota because the variety of distinct function calls on the main image is smaller than when tracing all images, thus compression performs better on \parlotm.
Also by looking at Fig. \ref{comet_chartAvg_bw_B_p3_5}, Fig. \ref{comet_chartAvg_bw_C_p3_5}, Fig. \ref{comet_chartAvg_cr_B_p3_5} and Fig. \ref{comet_chartAvg_cr_C_p3_5}, we find EP to have the highest compression ratio of the NPB applications. At the same time, it has the minimum required bandwidth. The opposite is true for CG, which exhibits the lowest compression ratio and the highest required bandwidth. CG is a conjugate gradient method with irregular memory accesses and communications whereas EP is an embarrassingly parallel random number generator. CG's whole-program trace contains a larger number of distinct calls and more complex patterns than that of EP, thus resulting in a higher bandwidth and lower compression ratio.
%

\parlot's compression mechanism works better on larger input sizes because larger inputs tend to result in longer streams of similar function calls (e.g., a call that is made for every processed element).



\subsection{Overheads}
\label{subsec:pinit}
Tables \ref{comet_wo_det_Main_all_B_p3.5} and
\ref{comet_wo_det_All_all_B_p3.5} present the average overhead added to each
application for different versions of \parlot.
%
The last row of these two tables
presents the geometric mean.
%
This information captures how much each
phase of \parlot slows down the native execution.

\input{parlot/tabs.comet.newMed/comet_wo_det_Main_all_B_p3.5.tex}

\input{parlot/tabs.comet.newMed/comet_wo_det_All_all_B_p3.5.tex}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[t]
\centering
\includegraphics[width=.7\textwidth]{parlot/figs.comet.newMed/comet_chartDet_B_woc_byTool_p3_5.png}
\caption{\parlotnc tracing overhead breakdown - Input B}
\label{comet_chartDet_B_woc_byTool_p3_5}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=.7\textwidth]{parlot/figs.comet.newMed/comet_chartDet_C_woc_byTool_p3_5.png}
\caption{ \parlotnc tracing overhead breakdown - Input C}
\label{comet_chartDet_C_woc_byTool_p3_5}
\end{figure}

In general, one
expects the following inequality to hold:
 the overhead of \pininit should be less than that of \parlot
, which should be less than that of \parlotnc.
%
This is not always the case because of the non-deterministic runtimes of the applications.
%
In fact, the variability across three runs of each experiment
is shown in Fig. \ref{comet_BX2_Main_16_B_p3_5}
where we present the minimum, maximum and median overheads.
%
These
overheads are for input size B and 16 nodes.
%
This variability explains the seeming inconsistencies in  Tables
\ref{comet_wo_det_Main_all_B_p3.5} and
\ref{comet_wo_det_All_all_B_p3.5}.


On average, \pininit adds
an overhead of 3.28  and \parlota adds an overhead of 3.42.
%
This means that \textbf{almost 96\%
of \parlota's overhead is due to \pin}.
%
The results of \parlotm and
other inputs follow the same pattern
as shown in Fig. \ref{comet_chartDet_B_wc_byTool_p3_5} and \ref{comet_chartDet_C_wc_byTool_p3_5}.
%
The overhead that \parlot (excluding the overhead of \pininit) {\em adds}
to the applications is very small.
%
If we were to switch to a different
instrumentation tool that is not as general as \pin but more
lightweight, the overhead would potentially reduce drastically. \\


\subsection{Compression Impact}
\label{subsec:compact}

Fig. \ref{comet_chartDet_B_woc_byTool_p3_5} and Fig. \ref{comet_chartDet_C_woc_byTool_p3_5} show the  overhead breakdown of \parlotnc, which illustrate the impact of compression. They also highlight the importance of incorporating compression directly in the tracing tool.
%
On average, \parlotnc slows down the application execution almost \textbf{2x} more than \parlota.
%
The average overhead
across Table \ref{comet_wo_det_All_all_B_p3.5} for \parlota is \textbf{3.4}.
%
The  corresponding factor for \parlotnc is \textbf{6.6}.
%
The numbers of \parlotm and input C  follow the same pattern. For example, \parlotnc slows down the application execution almost \textbf{1.66x} more than \parlotm.
%

Clearly, compression not only lowers the storage requirement but also the overhead. This is important as it shows that the extra computation to perform the compression is more than amortized by the reduction in the amount of data that need to be written out.
%

This result validates our approach and highlights that incremental, on-the-fly compression is likely essential to make whole-program tracing possible at low overhead.
